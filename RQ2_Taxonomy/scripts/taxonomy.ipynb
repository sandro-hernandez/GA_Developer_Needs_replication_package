{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GitHub Actions Information Needs taxonomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three subsets of data. They correspond to filter by title, body, and tags. \n",
    "1. posts_by_title: Posts containing \"Github Actions\" or its variants in the question title (github actions, github-action, Github actions, Github-actions, Github Actions, Github-Actions).\n",
    "2. posts_by_body: Posts containing \"Github Actions\" or its variants in the question body.\n",
    "3. posts_by_tags: Posts tagged with any of of github actions tag list ('github-actions', 'building-github-actions', 'github-actions-self-hosted-runners', 'github-actions-runners', 'github-actions-services', 'github-actions-artifacts', 'github-actions-reusable-workflows', 'github-actions-workflows', 'github-actions-marketplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T17:33:57.111764700Z",
     "start_time": "2024-02-19T17:33:57.072760Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T17:33:59.585371Z",
     "start_time": "2024-02-19T17:33:57.117757300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Posts filtered by three filters: Title, Body, and tags.\n",
    "posts_by_title = pd.read_json('../data/raw_data/posts_by_title.json')\n",
    "posts_by_body = pd.read_json('../data/raw_data/posts_by_body.json')\n",
    "posts_by_tags = pd.read_json('../data/raw_data/posts_by_tags.json')\n",
    "posts_by_title.rename(columns={\"CONCAT('https://stackoverflow.com/q/', p.Id)\": 'link'}, inplace=True)\n",
    "posts_by_body.rename(columns={\"CONCAT('https://stackoverflow.com/q/', p.Id)\": 'link'}, inplace=True)\n",
    "posts_by_tags.rename(columns={\"CONCAT('https://stackoverflow.com/q/', p.Id)\": 'link'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T17:33:59.603369100Z",
     "start_time": "2024-02-19T17:33:59.587380600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>post_type_id</th>\n",
       "      <th>accepted_answer_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>score</th>\n",
       "      <th>view_count</th>\n",
       "      <th>owner_user_id</th>\n",
       "      <th>last_editor_user_id</th>\n",
       "      <th>answer_count</th>\n",
       "      <th>comment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.873000e+03</td>\n",
       "      <td>9873.0</td>\n",
       "      <td>3.670000e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9873.000000</td>\n",
       "      <td>9873.000000</td>\n",
       "      <td>9.801000e+03</td>\n",
       "      <td>4.271000e+03</td>\n",
       "      <td>9873.000000</td>\n",
       "      <td>9873.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.126080e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.022708e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.747392</td>\n",
       "      <td>2217.544718</td>\n",
       "      <td>8.707827e+06</td>\n",
       "      <td>6.605726e+06</td>\n",
       "      <td>0.981363</td>\n",
       "      <td>1.657753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.184317e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.424942e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.666862</td>\n",
       "      <td>8988.151347</td>\n",
       "      <td>6.554179e+06</td>\n",
       "      <td>6.039375e+06</td>\n",
       "      <td>1.119418</td>\n",
       "      <td>2.394376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.417676e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.417763e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.100000e+01</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.796411e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.622763e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>2.628868e+06</td>\n",
       "      <td>1.623876e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.263306e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.129186e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>459.000000</td>\n",
       "      <td>7.764329e+06</td>\n",
       "      <td>4.290962e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.562319e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.493441e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1385.000000</td>\n",
       "      <td>1.383621e+07</td>\n",
       "      <td>1.023495e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.759369e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.758567e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>321529.000000</td>\n",
       "      <td>2.302257e+07</td>\n",
       "      <td>2.296569e+07</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  post_type_id  accepted_answer_id  parent_id        score  \\\n",
       "count  9.873000e+03        9873.0        3.670000e+03        0.0  9873.000000   \n",
       "mean   7.126080e+07           1.0        7.022708e+07        NaN     2.747392   \n",
       "std    5.184317e+06           0.0        5.424942e+06        NaN    11.666862   \n",
       "min    5.417676e+07           1.0        5.417763e+07        NaN    -6.000000   \n",
       "25%    6.796411e+07           1.0        6.622763e+07        NaN     0.000000   \n",
       "50%    7.263306e+07           1.0        7.129186e+07        NaN     1.000000   \n",
       "75%    7.562319e+07           1.0        7.493441e+07        NaN     2.000000   \n",
       "max    7.759369e+07           1.0        7.758567e+07        NaN   348.000000   \n",
       "\n",
       "          view_count  owner_user_id  last_editor_user_id  answer_count  \\\n",
       "count    9873.000000   9.801000e+03         4.271000e+03   9873.000000   \n",
       "mean     2217.544718   8.707827e+06         6.605726e+06      0.981363   \n",
       "std      8988.151347   6.554179e+06         6.039375e+06      1.119418   \n",
       "min         5.000000   9.100000e+01        -1.000000e+00      0.000000   \n",
       "25%       136.000000   2.628868e+06         1.623876e+06      0.000000   \n",
       "50%       459.000000   7.764329e+06         4.290962e+06      1.000000   \n",
       "75%      1385.000000   1.383621e+07         1.023495e+07      1.000000   \n",
       "max    321529.000000   2.302257e+07         2.296569e+07     35.000000   \n",
       "\n",
       "       comment_count  \n",
       "count    9873.000000  \n",
       "mean        1.657753  \n",
       "std         2.394376  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         1.000000  \n",
       "75%         2.000000  \n",
       "max        26.000000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_by_body = posts_by_body[posts_by_body['post_type_id']==1] # Keeping only post bodies that correspond to question bodies, removing answers bodies.\n",
    "posts_by_tags.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T17:33:59.874364900Z",
     "start_time": "2024-02-19T17:33:59.662362900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts filtered by title: 4538\n",
      "Number of posts filtered by body: 6297\n",
      "Number of posts filtered by tags : 9873\n",
      "Number of posts of the union: 11323\n",
      "Number of posts of the intersection: 2903\n"
     ]
    }
   ],
   "source": [
    "# Number of different datasets\n",
    "print(\"Number of posts filtered by title:\", len(posts_by_title))\n",
    "print(\"Number of posts filtered by body:\", len(posts_by_body))\n",
    "print(\"Number of posts filtered by tags :\", len(posts_by_tags))\n",
    "df_union = pd.concat([posts_by_tags, posts_by_title, posts_by_body]).drop_duplicates().reset_index(drop=True)\n",
    "print(\"Number of posts of the union:\", len(df_union))\n",
    "df_merged_1 = pd.merge(posts_by_tags, posts_by_title, how='inner')\n",
    "df_intersection = pd.merge(df_merged_1, posts_by_body, how='inner')\n",
    "print(\"Number of posts of the intersection:\", len(df_intersection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save intersection dataset\n",
    "df_intersection.to_csv('../data/processed_data/intersection.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have decided to use df_intersection because we consider that we are ensuring that the topic is for sure related to GitHub Actions because it is tagged and mentioned in the title and the body question. \n",
    "\n",
    "- We decided to select a random sample.\n",
    "\n",
    "- 340 posts or more are needed to have a confidence level of 95% that the real value is within ±5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T17:34:00.075360900Z",
     "start_time": "2024-02-19T17:33:59.975360800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample length:  400\n"
     ]
    }
   ],
   "source": [
    "# Creating the random sample. We are accepting the first 340 posts that we consider are related to the topic.\n",
    "sample_size = 400\n",
    "seed = 0\n",
    "df_sample = df_intersection.sample(n=sample_size, random_state=seed)\n",
    "print(\"Sample length: \", df_sample.shape[0])\n",
    "df_sample.head();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Manual examination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Two authors examinated the posts manually in order the removing posts that were not GA related or links that did not work. Finally, 340 posts were accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-19T17:34:00.097367700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Posts that are accepted by both evaluators were accepted.\n",
    "sample_reviewed=pd.read_excel('../data/raw_data/sample_eval1_reviewed.xlsx')\n",
    "sample_reviewed['evaluator2']=pd.read_excel('../data/raw_data/sample_eval2_reviewed.xlsx')['evaluator2']\n",
    "sample_accepted=sample_reviewed[(sample_reviewed['evaluator1']==1)&(sample_reviewed['evaluator2']==1)].head(340)\n",
    "sample_accepted = pd.merge(df_intersection, sample_accepted[['id']], on='id', how='inner')\n",
    "sample_accepted.to_excel('../data/processed_data/sample_accepted.xlsx')\n",
    "sample_accepted.head(3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Coding in sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Body text was parsed from html to plain text. Removing code, blocks, or links. Usually images are also links. After that, text was divided in sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def html_to_sentences_df(html_content):\n",
    "    \"\"\"\n",
    "    Parses the provided HTML content, replaces specific tags with placeholders, adjusts paragraph endings, and splits the content into sentences. \n",
    "    Returns a pandas DataFrame with each sentence in a separate row.\n",
    "    \n",
    "    Parameters:\n",
    "    - html_content: String containing HTML content.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with each sentence as a separate row.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Parse the HTML\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Replace code blocks, blockquotes, and links with placeholders\n",
    "    for code in soup.find_all('code'):\n",
    "        code.replace_with(\"-CODE-\")\n",
    "    for blockquote in soup.find_all('blockquote'):\n",
    "        blockquote.replace_with(\"-BLOCK-\")\n",
    "    for a in soup.find_all('a'):\n",
    "        a.replace_with(\"-LINK-\")\n",
    "\n",
    "    # Extract text and replace newline entities\n",
    "    text = soup.get_text()\n",
    "    text = text.replace('&#xA;', '\\n').strip()\n",
    "\n",
    "    # Pre-process text to handle ':\\\\n-CODE-' pattern\n",
    "    text = re.sub(r':\\s*\\n-CODE-', ': -CODE-', text)\n",
    "    text = re.sub(r':\\s*\\n-BLOCK-', ': -BLOCK-', text)\n",
    "    text = re.sub(r':\\s*\\n-LINK-', ': -LINK-', text)\n",
    "    \n",
    "    # Adjust paragraph endings where necessary\n",
    "    pattern = r'(?<![\\.\\!\\?\\s])\\s*\\n'\n",
    "    text = re.sub(pattern, '.\\n', text)\n",
    "\n",
    "    # Replace ':.' with ':'\n",
    "    text = text.replace(':.', ':')\n",
    "\n",
    "    # Split text into sentences\n",
    "    sentences = re.split(r'(?<=[.!?]) +', text.replace('\\n', ' '))\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(sentences, columns=['sentence'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shern\\AppData\\Local\\Temp\\ipykernel_32928\\190409919.py:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n",
      "C:\\Users\\shern\\AppData\\Local\\Temp\\ipykernel_32928\\190409919.py:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n",
      "C:\\Users\\shern\\AppData\\Local\\Temp\\ipykernel_32928\\190409919.py:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n",
      "C:\\Users\\shern\\AppData\\Local\\Temp\\ipykernel_32928\\190409919.py:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n",
      "C:\\Users\\shern\\AppData\\Local\\Temp\\ipykernel_32928\\190409919.py:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n",
      "C:\\Users\\shern\\AppData\\Local\\Temp\\ipykernel_32928\\190409919.py:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n",
      "C:\\Users\\shern\\AppData\\Local\\Temp\\ipykernel_32928\\190409919.py:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n",
      "C:\\Users\\shern\\AppData\\Local\\Temp\\ipykernel_32928\\190409919.py:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n",
      "C:\\Users\\shern\\AppData\\Local\\Temp\\ipykernel_32928\\190409919.py:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n",
      "C:\\Users\\shern\\AppData\\Local\\Temp\\ipykernel_32928\\190409919.py:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n",
      "C:\\Users\\shern\\AppData\\Local\\Temp\\ipykernel_32928\\190409919.py:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n",
      "C:\\Users\\shern\\AppData\\Local\\Temp\\ipykernel_32928\\190409919.py:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n",
      "C:\\Users\\shern\\AppData\\Local\\Temp\\ipykernel_32928\\190409919.py:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n",
      "C:\\Users\\shern\\AppData\\Local\\Temp\\ipykernel_32928\\190409919.py:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n",
      "C:\\Users\\shern\\AppData\\Local\\Temp\\ipykernel_32928\\190409919.py:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n",
      "C:\\Users\\shern\\AppData\\Local\\Temp\\ipykernel_32928\\190409919.py:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n",
      "C:\\Users\\shern\\AppData\\Local\\Temp\\ipykernel_32928\\190409919.py:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n",
      "C:\\Users\\shern\\AppData\\Local\\Temp\\ipykernel_32928\\190409919.py:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n",
      "C:\\Users\\shern\\AppData\\Local\\Temp\\ipykernel_32928\\190409919.py:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n",
      "C:\\Users\\shern\\AppData\\Local\\Temp\\ipykernel_32928\\190409919.py:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n",
      "C:\\Users\\shern\\AppData\\Local\\Temp\\ipykernel_32928\\190409919.py:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n",
      "C:\\Users\\shern\\AppData\\Local\\Temp\\ipykernel_32928\\190409919.py:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>source</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>57503578</td>\n",
       "      <td>title</td>\n",
       "      <td>Making pull requests to a GitHub repository au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>57503578</td>\n",
       "      <td>body</td>\n",
       "      <td>I have a file in a GitHub repository that need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>57503578</td>\n",
       "      <td>body</td>\n",
       "      <td>As part of a -LINK-, I want to have a bot runn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>57503578</td>\n",
       "      <td>body</td>\n",
       "      <td>I have a suspicion that the -LINK- can help me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>57503578</td>\n",
       "      <td>body</td>\n",
       "      <td>I see some official automation workflows that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>339</td>\n",
       "      <td>77519735</td>\n",
       "      <td>body</td>\n",
       "      <td>-CODE-.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>339</td>\n",
       "      <td>77519735</td>\n",
       "      <td>body</td>\n",
       "      <td>Below is an error message.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3173</th>\n",
       "      <td>339</td>\n",
       "      <td>77519735</td>\n",
       "      <td>body</td>\n",
       "      <td>-CODE-.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>339</td>\n",
       "      <td>77519735</td>\n",
       "      <td>body</td>\n",
       "      <td>I searched for an error message, but I couldn'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3175</th>\n",
       "      <td>339</td>\n",
       "      <td>77519735</td>\n",
       "      <td>body</td>\n",
       "      <td>How do I make modifications to work normally?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3176 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   post_id source                                           sentence\n",
       "0       0  57503578  title  Making pull requests to a GitHub repository au...\n",
       "1       0  57503578   body  I have a file in a GitHub repository that need...\n",
       "2       0  57503578   body  As part of a -LINK-, I want to have a bot runn...\n",
       "3       0  57503578   body  I have a suspicion that the -LINK- can help me...\n",
       "4       0  57503578   body  I see some official automation workflows that ...\n",
       "...   ...       ...    ...                                                ...\n",
       "3171  339  77519735   body                                            -CODE-.\n",
       "3172  339  77519735   body                         Below is an error message.\n",
       "3173  339  77519735   body                                            -CODE-.\n",
       "3174  339  77519735   body  I searched for an error message, but I couldn'...\n",
       "3175  339  77519735   body      How do I make modifications to work normally?\n",
       "\n",
       "[3176 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_df(sample_df):\n",
    "    # Initialize an empty DataFrame to hold all sentences\n",
    "    all_sentences_df = pd.DataFrame()\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in sample_df.iterrows():\n",
    "\n",
    "        # Process the title and body, assuming they are HTML content\n",
    "        title_sentences_df = html_to_sentences_df(row['post_title'])\n",
    "        body_sentences_df = html_to_sentences_df(row['post_body'])\n",
    "\n",
    "        # Add a column with the index/id of the post\n",
    "        title_sentences_df['id'] = index\n",
    "        body_sentences_df['id'] = index\n",
    "\n",
    "        # Add a column with the index/id of the post\n",
    "        title_sentences_df['post_id'] = row['id']\n",
    "        body_sentences_df['post_id'] = row['id']\n",
    "\n",
    "        # Add a column to indicate the source of the sentences\n",
    "        title_sentences_df['source'] = 'title'\n",
    "        body_sentences_df['source'] = 'body'\n",
    "        \n",
    "        # Combine title and body sentences\n",
    "        combined_sentences_df = pd.concat([title_sentences_df, body_sentences_df], ignore_index=True)\n",
    "        \n",
    "        # Add the combined sentences to the overall DataFrame\n",
    "        all_sentences_df = pd.concat([all_sentences_df, combined_sentences_df], ignore_index=True)\n",
    "\n",
    "        all_sentences_df = all_sentences_df[['id', 'post_id', 'source', 'sentence']]\n",
    "\n",
    "    return all_sentences_df\n",
    "\n",
    "all_sentences_df = process_df(sample_accepted) # this df contains all the sentences from the sample of 340 posts.\n",
    "\n",
    "all_sentences_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Manual classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing manually the taxonomy, we identified 8 Information Needs (DN), and 24 Relevant Information (RI) groups. \n",
    "The 8 DN are: Error Handling (EH), Incompatibility (IN), Insufficient Implementation (II), Migration (MI), Functionality Implementation (FI), Orientation (OR), Alternative Solution (AS), and GHA Learning (LE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "DN_list = ['EH', 'IN', 'II', 'MI', 'FI', 'OR', 'AS', 'LE']\n",
    "sentences_classified = pd.read_excel(\"../data/processed_data/sentences_taxonomy.xlsx\", sheet_name=DN_list)\n",
    "sample_sentences = pd.DataFrame()\n",
    "for k in sentences_classified.keys():\n",
    "    sentences_classified[k].drop_duplicates(inplace=True)\n",
    "    sample_sentences = pd.concat([sample_sentences, sentences_classified[k]], ignore_index=True)\n",
    "sample_sentences = pd.concat([sample_sentences, pd.get_dummies(sample_sentences['RI_id'], dtype=int)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentences.sort_values(by=['sentence_id'], inplace=True)\n",
    "sample_sentences.drop(['RI_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Relevant Information id's\n",
    "RI_list = sample_sentences.columns[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging duplicated sentences with different RI categories.\n",
    "agg_dict = dict()\n",
    "agg_dict['id'] = 'first'\n",
    "agg_dict['post_id'] = 'first'\n",
    "agg_dict['source'] = 'first'\n",
    "agg_dict['sentence'] = 'first'\n",
    "agg_dict.update({col: 'sum' for col in RI_list})\n",
    "sample_sentences = sample_sentences.groupby('sentence_id').agg(agg_dict).reset_index()\n",
    "sample_sentences;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1000 sentences that contain one or more types of Relevant Information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>source</th>\n",
       "      <th>sentence</th>\n",
       "      <th>AS1</th>\n",
       "      <th>EH1</th>\n",
       "      <th>EH2</th>\n",
       "      <th>EH3</th>\n",
       "      <th>EH4</th>\n",
       "      <th>EH5</th>\n",
       "      <th>...</th>\n",
       "      <th>II1</th>\n",
       "      <th>IN1</th>\n",
       "      <th>LE1</th>\n",
       "      <th>LE2</th>\n",
       "      <th>MI1</th>\n",
       "      <th>OR1</th>\n",
       "      <th>OR2</th>\n",
       "      <th>OR3</th>\n",
       "      <th>OR4</th>\n",
       "      <th>OR5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>57503578</td>\n",
       "      <td>title</td>\n",
       "      <td>Making pull requests to a GitHub repository au...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>57503578</td>\n",
       "      <td>body</td>\n",
       "      <td>I have a file in a GitHub repository that need...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>57503578</td>\n",
       "      <td>body</td>\n",
       "      <td>As part of a -LINK-, I want to have a bot runn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>57503578</td>\n",
       "      <td>body</td>\n",
       "      <td>I have a suspicion that the -LINK- can help me...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>57503578</td>\n",
       "      <td>body</td>\n",
       "      <td>I see some official automation workflows that ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>339</td>\n",
       "      <td>77519735</td>\n",
       "      <td>body</td>\n",
       "      <td>-CODE-.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>339</td>\n",
       "      <td>77519735</td>\n",
       "      <td>body</td>\n",
       "      <td>Below is an error message.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3173</th>\n",
       "      <td>339</td>\n",
       "      <td>77519735</td>\n",
       "      <td>body</td>\n",
       "      <td>-CODE-.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>339</td>\n",
       "      <td>77519735</td>\n",
       "      <td>body</td>\n",
       "      <td>I searched for an error message, but I couldn'...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3175</th>\n",
       "      <td>339</td>\n",
       "      <td>77519735</td>\n",
       "      <td>body</td>\n",
       "      <td>How do I make modifications to work normally?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3176 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id   post_id source  \\\n",
       "sentence_id                         \n",
       "0              0  57503578  title   \n",
       "1              0  57503578   body   \n",
       "2              0  57503578   body   \n",
       "3              0  57503578   body   \n",
       "4              0  57503578   body   \n",
       "...          ...       ...    ...   \n",
       "3171         339  77519735   body   \n",
       "3172         339  77519735   body   \n",
       "3173         339  77519735   body   \n",
       "3174         339  77519735   body   \n",
       "3175         339  77519735   body   \n",
       "\n",
       "                                                      sentence  AS1  EH1  EH2  \\\n",
       "sentence_id                                                                     \n",
       "0            Making pull requests to a GitHub repository au...    0    0    0   \n",
       "1            I have a file in a GitHub repository that need...    0    0    0   \n",
       "2            As part of a -LINK-, I want to have a bot runn...    0    0    0   \n",
       "3            I have a suspicion that the -LINK- can help me...    0    0    0   \n",
       "4            I see some official automation workflows that ...    0    0    0   \n",
       "...                                                        ...  ...  ...  ...   \n",
       "3171                                                   -CODE-.    0    0    0   \n",
       "3172                                Below is an error message.    0    0    0   \n",
       "3173                                                   -CODE-.    0    0    0   \n",
       "3174         I searched for an error message, but I couldn'...    0    0    0   \n",
       "3175             How do I make modifications to work normally?    0    0    0   \n",
       "\n",
       "             EH3  EH4  EH5  ...  II1  IN1  LE1  LE2  MI1  OR1  OR2  OR3  OR4  \\\n",
       "sentence_id                 ...                                                \n",
       "0              0    0    0  ...    0    0    0    0    0    0    0    0    0   \n",
       "1              0    0    0  ...    0    0    0    0    0    0    0    0    0   \n",
       "2              0    0    0  ...    0    0    0    0    0    0    0    0    0   \n",
       "3              0    0    0  ...    0    0    0    0    0    0    0    0    0   \n",
       "4              0    0    0  ...    0    0    0    0    0    0    0    0    0   \n",
       "...          ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "3171           0    0    0  ...    0    0    0    0    0    0    0    0    0   \n",
       "3172           0    0    0  ...    0    0    0    0    0    0    0    0    0   \n",
       "3173           0    0    0  ...    0    0    0    0    0    0    0    0    0   \n",
       "3174           0    0    0  ...    0    0    0    0    0    0    0    0    0   \n",
       "3175           0    0    0  ...    0    0    1    0    0    0    0    0    0   \n",
       "\n",
       "             OR5  \n",
       "sentence_id       \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "...          ...  \n",
       "3171           0  \n",
       "3172           0  \n",
       "3173           0  \n",
       "3174           0  \n",
       "3175           0  \n",
       "\n",
       "[3176 rows x 25 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DF with all the sentences of the sample and their categorization\n",
    "\n",
    "# Add each new column filled with zeros to the DataFrame\n",
    "for column in RI_list:\n",
    "    all_sentences_df[column] = 0\n",
    "all_sentences_df.index.name = 'sentence_id'\n",
    "\n",
    "for i in range(len(all_sentences_df)):\n",
    "    for j in range(len(sample_sentences)):\n",
    "        if i == sample_sentences.loc[j, 'sentence_id']:\n",
    "            all_sentences_df.loc[i, RI_list] = sample_sentences.loc[j, RI_list]\n",
    "all_sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the 'tags' column only if the tags are not lists\n",
    "if isinstance(sample_accepted['tags'].iloc[0], str):\n",
    "    def extract_tags(tags_str):\n",
    "        return tags_str.strip('<>').split('><')\n",
    "    sample_accepted['tags'] = sample_accepted['tags'].apply(extract_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames on 'post_id' (from all_sentences_df) and 'id' (from sample_accepted)\n",
    "sentence_analysis_df = pd.merge(all_sentences_df, sample_accepted, left_on='post_id', right_on='id', how='left')\n",
    "# Drop the redundant 'id_y' column\n",
    "sentence_analysis_df.drop(['id_y'], axis=1, inplace=True)\n",
    "# Rename 'id_x' to 'sample_id'\n",
    "sentence_analysis_df.rename(columns={'id_x': 'sample_id'}, inplace=True)\n",
    "# Save the merged DataFrame to an Excel file with the new name\n",
    "sentence_analysis_df.to_excel(f'../results/sentences_classified.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Results and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping from RI columns to DN categories\n",
    "dn_mapping = {\n",
    "    'EH': ['EH1', 'EH2', 'EH3', 'EH4', 'EH5', 'EH6', 'EH7', 'EH8', 'EH9'],\n",
    "    'IN': ['IN1'],\n",
    "    'II': ['II1'],\n",
    "    'MI': ['MI1'],\n",
    "    'FI': ['FI1'],\n",
    "    'OR': ['OR1', 'OR2', 'OR3', 'OR4', 'OR5'],\n",
    "    'AS': ['AS1'],\n",
    "    'LE': ['LE1', 'LE2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences: 3176\n",
      "Number of sentences with any RI: 1005\n",
      "Number of sentences without any RI: 2171\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of sentences\n",
    "total_sentences = all_sentences_df.shape[0]\n",
    "\n",
    "# Calculate the number of sentences without any RI\n",
    "ri_columns = [col for sublist in dn_mapping.values() for col in sublist]\n",
    "sentences_without_ri = all_sentences_df[ri_columns].sum(axis=1) == 0\n",
    "num_sentences_without_ri = sentences_without_ri.sum()\n",
    "\n",
    "# Display the results\n",
    "print(f\"Total number of sentences: {total_sentences}\")\n",
    "print(f\"Number of sentences with any RI: {total_sentences - num_sentences_without_ri}\")\n",
    "print(f\"Number of sentences without any RI: {num_sentences_without_ri}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI_Category</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AS1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EH1</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EH2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EH3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EH4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EH5</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EH6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EH7</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EH8</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EH9</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FI1</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>II1</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>IN1</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LE1</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LE2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MI1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>OR1</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>OR2</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OR3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>OR4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>OR5</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RI_Category  Count\n",
       "0          AS1      9\n",
       "1          EH1     98\n",
       "2          EH2      8\n",
       "3          EH3      4\n",
       "4          EH4     14\n",
       "5          EH5     80\n",
       "6          EH6     12\n",
       "7          EH7     67\n",
       "8          EH8     63\n",
       "9          EH9     61\n",
       "10         FI1    196\n",
       "11         II1    102\n",
       "12         IN1     63\n",
       "13         LE1    150\n",
       "14         LE2      8\n",
       "15         MI1     14\n",
       "16         OR1     70\n",
       "17         OR2     41\n",
       "18         OR3     20\n",
       "19         OR4     10\n",
       "20         OR5     44"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the counts for each RI category\n",
    "ri_columns = all_sentences_df.columns[4:]  # Assuming RI columns start from the 5th column onwards\n",
    "ri_counts = all_sentences_df[ri_columns].sum()\n",
    "\n",
    "# Convert the counts to a DataFrame for better readability\n",
    "ri_counts_df = ri_counts.reset_index()\n",
    "ri_counts_df.columns = ['RI_Category', 'Count']\n",
    "\n",
    "ri_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FI1    154\n",
       "LE1    118\n",
       "II1     86\n",
       "EH1     78\n",
       "EH5     70\n",
       "OR1     61\n",
       "EH7     61\n",
       "EH8     50\n",
       "EH9     50\n",
       "IN1     48\n",
       "OR2     34\n",
       "OR5     33\n",
       "OR3     19\n",
       "EH4     14\n",
       "MI1     12\n",
       "EH6     11\n",
       "OR4     10\n",
       "AS1      9\n",
       "LE2      8\n",
       "EH2      6\n",
       "EH3      4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of posts that have each RI category\n",
    "ri_post_counts = all_sentences_df.groupby('post_id')[ri_columns].sum()\n",
    "ri_post_counts = (ri_post_counts > 0).sum().sort_values(ascending=False)\n",
    "ri_post_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unique Post Count  Percentage\n",
      "EH                182   53.529412\n",
      "FI                154   45.294118\n",
      "OR                134   39.411765\n",
      "LE                121   35.588235\n",
      "II                 86   25.294118\n",
      "IN                 48   14.117647\n",
      "MI                 12    3.529412\n",
      "AS                  9    2.647059\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of unique posts\n",
    "total_posts = all_sentences_df['post_id'].nunique()\n",
    "\n",
    "# Initialize a dictionary to store the count of unique posts for each DN\n",
    "dn_unique_post_counts = {dn: 0 for dn in dn_mapping.keys()}\n",
    "\n",
    "# Calculate the number of unique posts that have each DN category\n",
    "for dn, ri_list in dn_mapping.items():\n",
    "    dn_unique_post_counts[dn] = (all_sentences_df.groupby('post_id')[ri_list].sum() > 0).any(axis=1).sum()\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "dn_unique_post_counts_df = pd.DataFrame.from_dict(dn_unique_post_counts, orient='index', columns=['Unique Post Count'])\n",
    "\n",
    "# Calculate the percentage of total posts\n",
    "dn_unique_post_counts_df['Percentage'] = (dn_unique_post_counts_df['Unique Post Count'] / total_posts) * 100\n",
    "\n",
    "# Sort the DataFrame by the count of unique posts in descending order\n",
    "dn_unique_post_counts_df = dn_unique_post_counts_df.sort_values(by='Unique Post Count', ascending=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(dn_unique_post_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unique Sentence Count\n",
      "FI1                    196\n",
      "LE1                    150\n",
      "II1                    102\n",
      "EH1                     98\n",
      "EH5                     80\n",
      "OR1                     70\n",
      "EH7                     67\n",
      "IN1                     63\n",
      "EH8                     63\n",
      "EH9                     61\n",
      "OR5                     44\n",
      "OR2                     41\n",
      "OR3                     20\n",
      "EH4                     14\n",
      "MI1                     14\n",
      "EH6                     12\n",
      "OR4                     10\n",
      "AS1                      9\n",
      "LE2                      8\n",
      "EH2                      8\n",
      "EH3                      4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unique Sentence Count    1134\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of unique sentences per RI category\n",
    "ri_unique_sentence_counts = {ri: (all_sentences_df[ri] > 0).sum() for ri in ri_columns}\n",
    "\n",
    "# Convert the dictionary to a DataFrame for display\n",
    "ri_unique_sentence_counts_df = pd.DataFrame.from_dict(ri_unique_sentence_counts, orient='index', columns=['Unique Sentence Count']).sort_values(by='Unique Sentence Count', ascending=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(ri_unique_sentence_counts_df)\n",
    "\n",
    "ri_unique_sentence_counts_df.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
